package practice.practicecamera.special.camera

import android.Manifest
import android.app.Activity
import android.content.Context
import android.content.pm.PackageManager
import android.content.res.Configuration
import android.graphics.ImageFormat
import android.graphics.Matrix
import android.graphics.Point
import android.graphics.RectF
import android.graphics.SurfaceTexture
import android.hardware.camera2.CameraAccessException
import android.hardware.camera2.CameraCaptureSession
import android.hardware.camera2.CameraCharacteristics
import android.hardware.camera2.CameraDevice
import android.hardware.camera2.CameraManager
import android.hardware.camera2.CameraMetadata
import android.hardware.camera2.CaptureRequest
import android.hardware.camera2.CaptureResult
import android.hardware.camera2.TotalCaptureResult
import android.media.ImageReader
import android.net.Uri
import android.os.Handler
import android.os.HandlerThread
import android.support.v4.app.ActivityCompat
import android.support.v4.app.Fragment
import android.support.v4.content.ContextCompat
import android.util.Size
import android.view.Surface
import android.view.TextureView
import practice.practicecamera.ui.AutoFitTextureView
import java.io.File
import java.util.*
import java.util.concurrent.Semaphore
import java.util.concurrent.TimeUnit

class CameraControl
{
    //region Private Properties

    private var activity: Activity? = null
    private var textureVw: AutoFitTextureView? = null
    private var delegate: CameraControlDelegate? = null
    private var imgReader: ImageReader? = null   //Reads taken images to files
    private var oFile: File? = null //Output file for the picture
    private lateinit var currentCameraID: String
    private var capSesh: CameraCaptureSession? = null
    private var currentCameraDevice: CameraDevice? = null
    private lateinit var previewSize: Size
    private var backgroundThread: HandlerThread? = null         //Prevents UI blocking
    private var backgroundHandler: Handler? = null              //Handles background tasks
    private var previewReqBuilder: CaptureRequest.Builder? = null
    private var previewReq: CaptureRequest? = null              //Gets generated by the req builder
    private var currentCamState = CameraControl.STATE_PREVIEW
    private val cameraOpenCloseSemaphore = Semaphore(1) //Prevents exits before cam shutoff
    private var flashIsSupported: Boolean = false
    private var sensorOrientation: Int? = null

    //endregion
    //region Private Camera Callback Properties

    /**
     * This a callback object for the [ImageReader]. "onImageAvailable" will be called when a
     * still image is ready to be saved.
     */
    private var onImageAvailableListener = ImageReader.OnImageAvailableListener { reader ->
        val act = activity

        //TODO
        if (act != null)
        {
            val oFile = File(act.getExternalFilesDir(null), OUTPUT_FILE_NAME)
            oFile.delete()
            oFile.createNewFile()
            val nextImage = reader.acquireNextImage()
            if (oFile != null && nextImage != null)
            {
                println("image reader is available")
                backgroundHandler?.post(
                        CameraUtilImageSaver(
                                imgToSave = nextImage,
                                imgOFile = oFile
                        )
                )
            }
            else
            {
                println("either ofile or next image is null")
            }
        }
    }

    private val surfaceTextureListener = object : TextureView.SurfaceTextureListener
    {
        override fun onSurfaceTextureAvailable(texture: SurfaceTexture, width: Int, height: Int)
        {
            activateCurrentCamera(width = width, height = height)
        }

        override fun onSurfaceTextureSizeChanged(texture: SurfaceTexture, width: Int, height: Int)
        {
            configureTransform(viewWidth = width, viewHeight = height)
        }

        override fun onSurfaceTextureDestroyed(texture: SurfaceTexture): Boolean = true

        override fun onSurfaceTextureUpdated(texture: SurfaceTexture) = Unit
    }

    /**
     * [CameraDevice.StateCallback] is called when [CameraDevice] changes its state.
     */
    private val cameraStateCallback = object : CameraDevice.StateCallback()
    {
        override fun onOpened(cameraDevice: CameraDevice)
        {
            //This method is called when the camera is opened. Start the camera preview here.
            cameraOpenCloseSemaphore.release()
            currentCameraDevice = cameraDevice
            createCameraPreviewSession()
        }

        override fun onDisconnected(cameraDevice: CameraDevice)
        {
            cameraOpenCloseSemaphore.release()
            cameraDevice.close()
            currentCameraDevice = null
        }

        override fun onError(cameraDevice: CameraDevice, error: Int)
        {
            cameraOpenCloseSemaphore.release()
            cameraDevice.close()
            currentCameraDevice = null
            activity?.finish()  //TODO don't shut down, just show an error
        }
    }

    /**
     * A [CameraCaptureSession.CaptureCallback] that handles events related to JPEG capture.
     */
    private val capSeshCallback = object : CameraCaptureSession.CaptureCallback()
    {
        private fun process(result: CaptureResult)
        {
            when (currentCamState)
            {
                CameraControl.STATE_PREVIEW                ->
                {
                    //Nothing to do when the camera preview is working normally.
                }
                CameraControl.STATE_WAITING_LOCK           ->
                {
                    val afState = result.get(CaptureResult.CONTROL_AF_STATE)
                    if (afState == null)
                    {
                        captureStillPicture()
                    }
                    else if (afState == CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED ||
                             afState == CaptureResult.CONTROL_AF_STATE_NOT_FOCUSED_LOCKED
                    )
                    {
                        //CONTROL_AE_STATE can be null on some devices
                        val aeState = result.get(CaptureResult.CONTROL_AE_STATE)
                        if (aeState == null || aeState == CaptureResult.CONTROL_AE_STATE_CONVERGED)
                        {
                            currentCamState = CameraControl.STATE_PICTURE_TAKEN
                            captureStillPicture()
                        }
                        else
                        {
                            runPrecaptureSequence()
                        }
                    }
                    else if (afState == CaptureResult.CONTROL_AF_STATE_INACTIVE)
                    {
                        currentCamState = CameraControl.STATE_PICTURE_TAKEN
                        captureStillPicture()
                    }
                }
                CameraControl.STATE_WAITING_PRECAPTURE     ->
                {
                    // CONTROL_AE_STATE can be null on some devices
                    val aeState = result.get(CaptureResult.CONTROL_AE_STATE)
                    if (aeState == null ||
                        aeState == CaptureResult.CONTROL_AE_STATE_PRECAPTURE ||
                        aeState == CaptureRequest.CONTROL_AE_STATE_FLASH_REQUIRED
                    )
                    {
                        currentCamState = CameraControl.STATE_WAITING_NON_PRECAPTURE
                    }
                }
                CameraControl.STATE_WAITING_NON_PRECAPTURE ->
                {
                    // CONTROL_AE_STATE can be null on some devices
                    val aeState = result.get(CaptureResult.CONTROL_AE_STATE)
                    if (aeState == null || aeState != CaptureResult.CONTROL_AE_STATE_PRECAPTURE)
                    {
                        currentCamState = CameraControl.STATE_PICTURE_TAKEN
                        captureStillPicture()
                    }
                }
            }
        }

        override fun onCaptureProgressed(
            session: CameraCaptureSession,
            request: CaptureRequest,
            partialResult: CaptureResult
        )
        {
            process(partialResult)
        }

        override fun onCaptureCompleted(
            session: CameraCaptureSession,
            request: CaptureRequest,
            result: TotalCaptureResult
        )
        {
            process(result)
        }

    }

    //endregion
    //region Associated

    interface CameraControlDelegate
    {
        fun cameraControlDidWantToExplainWhyCameraPermissionsAreNeeded(reason: String)
        fun cameraControlFinishedTakingPicture()
    }

    companion object
    {
        //region Shared Properties

        var lastPicTaken: Uri? = null
        private const val OUTPUT_FILE_NAME = "mostRecentPicTaken.jpg"

        //endregion
        //region Private Shared Properties
        //region Camera State "Enums"

        private const val STATE_PREVIEW = 0                 //Showing camera preview
        private const val STATE_WAITING_LOCK = 1            //Waiting for focus lock
        private const val STATE_WAITING_PRECAPTURE = 2      //Waiting for pre-capture exposure
        private const val STATE_WAITING_NON_PRECAPTURE = 3  //Waiting for any other pre-cap state
        private const val STATE_PICTURE_TAKEN = 4           //Pic was taken

        //endregion

        /**
         * Max preview width that is guaranteed by Camera2 API
         */
        private const val MAX_PREVIEW_WIDTH = 1920

        /**
         * Max preview height that is guaranteed by Camera2 API
         */
        private const val MAX_PREVIEW_HEIGHT = 1080
        private const val CAMERA_PERMISSION_REQ_CODE = 1

        /**
         * Android device manufacturers are inconsistent with how they install their camera
         * sensors. Sometimes, they're physically installed upside down or even sideways. This can
         * produce upside down/sideways pictures :/. For more info, look at whatever function uses
         * this property.
         */
        private val ORIENTATIONS = hashMapOf(
                Pair(Surface.ROTATION_0, 90),
                Pair(Surface.ROTATION_90, 0),
                Pair(Surface.ROTATION_180, 270),
                Pair(Surface.ROTATION_270, 180)
        )

        //endregion

        /**
         * Given {@code choices} of {@code Size}s supported by a camera, choose the smallest one
         * that is at least as large as the respective texture view size, and that is at most as
         * large as the respective max size, and whose aspect ratio matches with the specified
         * value. If such size doesn't exist, choose the largest one that is at most as large as
         * the respective max size, and whose aspect ratio matches with the specified value.
         *
         * @param choices           The list of sizes that the camera supports for the intended
         *                          output class
         * @param textureViewWidth  The width of the texture view relative to sensor coordinate
         * @param textureViewHeight The height of the texture view relative to sensor coordinate
         * @param maxWidth          The maximum width that can be chosen
         * @param maxHeight         The maximum height that can be chosen
         * @param aspectRatio       The aspect ratio
         * @return The optimal {@code Size}, or an arbitrary one if none were big enough
         */
//        private fun chooseOptimalSize(
//            choices: List<Size>, textureViewWidth: Int,
//            textureViewHeight: Int, maxWidth: Int, maxHeight: Int,
//            aspectRatio: Size
//        ): Size
//        {
//            val w = aspectRatio.width
//            val h = aspectRatio.height
//
//            //Collect the supported resolutions that are at least as big as the preview Surface
//            val bigEnough = arrayListOf<Size>()
//
//            //Collect the supported resolutions that are smaller than the preview Surface
//            val notBigEnough = arrayListOf<Size>()
//
//            for (option in choices)
//            {
//                if (option.width <= maxWidth && option.height <= maxHeight &&
//                    option.height == option.width * h / w
//                )
//                {
//                    if (option.width >= textureViewWidth &&
//                        option.height >= textureViewHeight
//                    )
//                    {
//                        bigEnough.add(option)
//                    }
//                    else
//                    {
//                        notBigEnough.add(option)
//                    }
//                }
//            }
//            // Pick the smallest of those big enough. If there is no one big enough, pick the
//            // largest of those not big enough.
//            return when
//            {
//                bigEnough.size > 0    -> Collections.min(
//                    bigEnough,
//                    CameraControl.CompareSizesByArea()
//                )
//                notBigEnough.size > 0 -> Collections.max(
//                    notBigEnough,
//                    CameraControl.CompareSizesByArea()
//                )
//                else                  ->
//                {
//                    //            Log.e(TAG, "Couldn't find any suitable preview size");
//                    //TODO Log dis
//                    choices[0]
//                }
//            }
//        }
        private fun chooseOptimalSize(choices: Array<Size>,
                                      textureViewWidth: Int,
                                      textureViewHeight: Int,
                                      maxWidth: Int,
                                      maxHeight: Int,
                                      aspectRatio: Size): Size
        {
            val bigEnough = ArrayList<Size>()       //Cam resolutions at least as big as surface
            val notBigEnough = ArrayList<Size>()    //Cam res's that are smaller than surface
            val w = aspectRatio.width
            val h = aspectRatio.height
            for (option in choices)
            {
                if (option.width <= maxWidth &&
                    option.height <= maxHeight &&
                    option.height == option.width * h / w)
                {
                    if (option.width >= textureViewWidth && option.height >= textureViewHeight)
                    {
                        bigEnough.add(option)
                    }
                    else
                    {
                        notBigEnough.add(option)
                    }
                }
            }
            //Choose smallest of those big enough, but if there are none big enough, pick the
            //largest of those not big enough
            return when
            {
                bigEnough.size > 0    -> Collections.min(bigEnough, CompareSizesByArea())
                notBigEnough.size > 0 -> Collections.max(notBigEnough, CompareSizesByArea())
                else                  ->
                {
                    println("Couldn't find any suitable preview size")
                    choices[0]
                }
            }
        }
    }

    /**
     * Comparator for Size objects based on their areas.
     */
    internal class CompareSizesByArea : Comparator<Size>
    {
        override fun compare(lhs: Size, rhs: Size): Int
        {
            // We cast here to ensure the multiplications won't overflow
            return java.lang.Long.signum(
                    lhs.width.toLong()
                    * lhs.height - rhs.width.toLong() * rhs.height
            )
        }
    }

    //endregion
    //region Lifecycle Dependent Functions

    fun performSetupWhenActivityCreated(activity: Activity?)
    {
        if (activity != null)
        {
            oFile = File(activity.getExternalFilesDir(null), OUTPUT_FILE_NAME)
        }
        else
        {
            TODO() //ERRROROREOREOIREOI
        }
    }

    fun performActionsOnResume(fragment: Fragment, textureVw: AutoFitTextureView?)
    {
        //Refresh volatile properties
        activity = fragment.activity
        this.textureVw = textureVw

        //Check delegate conformance and reassign
        if (fragment is CameraControlDelegate)
        {
            delegate = fragment
        }
        else
        {
            throw java.lang.RuntimeException(
                    fragment.toString() + " must implement CamerControlDelegate"
            )
        }
        startBackgroundThread()
        if (textureVw != null)  //TODO guard the texture view
        {
            // When the screen is turned off and turned back on, the SurfaceTexture is already
            // available, and "onSurfaceTextureAvailable" will not be called. In that case, we can
            // open a camera and start preview from here (otherwise, we wait until the surface is
            // ready in the SurfaceTextureListener).
            if (textureVw.isAvailable)
            {
                activateCurrentCamera(width = textureVw.width, height = textureVw.height)
            }
            else
            {
                textureVw.surfaceTextureListener = surfaceTextureListener
            }
        }
    }

    fun performActionsOnPause()
    {
        deactivateCurrentCamera()
        stopBackgroundThread()

        //Circular dependencies don't matter in Android, but whatever
        textureVw = null
        delegate = null
        activity = null
    }

    fun shouldHandleOnPermissionsRequestResult(requestCode: Int, grantResults: IntArray): Boolean
    {
        return (requestCode == CAMERA_PERMISSION_REQ_CODE &&
                (grantResults.size != 1 || grantResults[0] != PackageManager.PERMISSION_GRANTED))
    }

    fun handleOnPermissionsRequestResult()
    {
        println("ASK FOR LE PERMISSION DES")
        TODO() //Output R.string.request_permission which doesn't exist yet
    }

    //endregion
    //region Functions

    /**
     * Initiate a still image capture.
     */
    fun takePicture()
    {
        lockFocus()
    }

    //endregion
    //region Private Functions
    /**
     * Sets up member variables related to the camera.
     *
     * @param width  The width of available size for camera preview
     * @param height The height of available size for camera preview
     */
//    private fun setUpCameraOutputs(width: Int, height: Int)
//    {
//        val act = activity ?: return
//        val texVw = textureVw ?: return //TODO throw errors
//        val manager: CameraManager = act.getSystemService(Context.CAMERA_SERVICE)
//                as? CameraManager ?: return
//        val byArea = Comparator<Size> { lhs, rhs ->
//            //Cast to ensure the multiplications won't overflow
//            java.lang.Long.signum(
//                lhs.width.toLong() *
//                        lhs.height - rhs.width.toLong() *
//                        rhs.height
//            )
//        }
//
//        try
//        {
//            //Look for cameras
//            for (someCamID in manager.cameraIdList)
//            {
//                val charistics: CameraCharacteristics = manager.getCameraCharacteristics(someCamID)
//                val rearFacing: Int = charistics.get(CameraCharacteristics.LENS_FACING) ?: continue
////                if (rearFacing != null && rearFacing == CameraCharacteristics.LENS_FACING_FRONT)
////                {
////                    continue TODO
////                }
//                val map: StreamConfigurationMap = charistics.get(
//                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP
//                ) ?: continue
//                val outputSizes = map.getOutputSizes(ImageFormat.JPEG) ?: continue
//                val largestSize = outputSizes.maxWith(comparator = byArea) ?: continue
//                val resources = act.resources ?: return
//
//                imgReader = ImageReader.newInstance(
//                    largestSize.width, largestSize.height,
//                    ImageFormat.JPEG, 2
//                )
//                imgReader?.setOnImageAvailableListener(onImageAvailableListener, backgroundHandler)
//
//                //Dimens sometimes swap to get a correct preview relative to sensor coordinate
//                var dimensAreSwapped = false
//                val displayRotation = act.windowManager.defaultDisplay.rotation
//                val orient = charistics.get(CameraCharacteristics.SENSOR_ORIENTATION)
//                sensorOrientation = orient
//                if (orient != null)
//                {
//                    dimensAreSwapped = when (displayRotation)
//                    {
//                        Surface.ROTATION_0, Surface.ROTATION_180  -> orient == 90 || orient == 270
//                        Surface.ROTATION_90, Surface.ROTATION_270 -> orient == 0 || orient == 180
//                        else                                      -> TODO() //Report invalid rotation "Display rotation is invalid: " + displayRotation
//                    }
//                }
//                val displaySz = Point(); act.windowManager.defaultDisplay.getSize(displaySz)
//                var maxPreviewWidth = displaySz.x
//                var maxPreviewHeight = displaySz.y
//                var rotatedPreviewWidth = width
//                var rotatedPreviewHeight = height
//
//                if (dimensAreSwapped)
//                {
//                    rotatedPreviewWidth = height
//                    rotatedPreviewHeight = width
//                    maxPreviewWidth = displaySz.y
//                    maxPreviewHeight = displaySz.x
//                }
//                if (maxPreviewWidth > MAX_PREVIEW_WIDTH)
//                {
//                    maxPreviewWidth = MAX_PREVIEW_WIDTH
//                }
//                if (maxPreviewHeight > MAX_PREVIEW_HEIGHT)
//                {
//                    maxPreviewHeight = MAX_PREVIEW_HEIGHT
//                }
//                //Attempting to use too large a preview size could  exceed the camera bus'
//                //bandwidth limitation, resulting in gorgeous previews but the storage of garbage
//                //capture data
//                previewSize = chooseOptimalSize(
//                    outputSizes, rotatedPreviewWidth,
//                    rotatedPreviewHeight, maxPreviewWidth,
//                    maxPreviewHeight, largestSize
//                )
//
//                //Fit the aspect ratio of TextureView to the chosen size for the preview
//                val orientation = resources.configuration.orientation
//                if (orientation == Configuration.ORIENTATION_LANDSCAPE)
//                {
//                    texVw.setAspectRatio(previewSize.width, previewSize.height)
//                }
//                else
//                {
//                    texVw.setAspectRatio(previewSize.height, previewSize.width)
//                }
//                // Check if the flash is supported.
//                flashIsSupported = charistics.get(CameraCharacteristics.FLASH_INFO_AVAILABLE)
//                        ?: false
//
//                //Finally, remember the camera ID
//                currentCameraID = someCamID
//            }
//        } catch (e: CameraAccessException)
//        {
//            e.printStackTrace()
//            TODO() //LOG DIS
//        } catch (e: NullPointerException)
//        {
//            //Currently a NPE is thrown when the Camera2API is used but not supported on the
//            //device this code runs.
//            TODO() //FIGURE THIS OUT
//        }
//    }
    private fun setUpCameraOutputs(width: Int, height: Int)
    {
        val activity = activity ?: return
        val manager = activity.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try
        {
            for (cameraId in manager.cameraIdList)
            {
                val characteristics = manager.getCameraCharacteristics(cameraId)
                // We don't use a front facing camera in this sample.
                val cameraDirection = characteristics.get(CameraCharacteristics.LENS_FACING)
                if (cameraDirection != null &&
                    cameraDirection == CameraCharacteristics.LENS_FACING_FRONT
                )
                {
                    continue
                }
                val map = characteristics.get(
                        CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP
                ) ?: continue
                // For still image captures, we use the largest available size.
                val largest = Collections.max(
                        Arrays.asList(*map.getOutputSizes(ImageFormat.JPEG)),
                        CompareSizesByArea()
                )
                imgReader = ImageReader.newInstance(
                        largest.width, largest.height,
                        ImageFormat.JPEG, /*maxImages*/ 2
                ).apply {
                    setOnImageAvailableListener(onImageAvailableListener, backgroundHandler)
                }
                // Find out if we need to swap dimension to get the preview size relative to sensor
                // coordinate.
                val displayRotation = activity.windowManager.defaultDisplay.rotation
                sensorOrientation = characteristics.get(CameraCharacteristics.SENSOR_ORIENTATION)
                val swappedDimensions = areDimensionsSwapped(displayRotation)
                val displaySize = Point()
                activity.windowManager.defaultDisplay.getSize(displaySize)
                val rotatedPreviewWidth = if (swappedDimensions) height else width
                val rotatedPreviewHeight = if (swappedDimensions) width else height
                var maxPreviewWidth = if (swappedDimensions) displaySize.y else displaySize.x
                var maxPreviewHeight = if (swappedDimensions) displaySize.x else displaySize.y
                if (maxPreviewWidth > MAX_PREVIEW_WIDTH) maxPreviewWidth = MAX_PREVIEW_WIDTH
                if (maxPreviewHeight > MAX_PREVIEW_HEIGHT) maxPreviewHeight = MAX_PREVIEW_HEIGHT
                // Danger, W.R.! Attempting to use too large a preview size could  exceed the camera
                // bus' bandwidth limitation, resulting in gorgeous previews but the storage of
                // garbage capture data.
                previewSize = chooseOptimalSize(
                        map.getOutputSizes(SurfaceTexture::class.java),
                        rotatedPreviewWidth, rotatedPreviewHeight,
                        maxPreviewWidth, maxPreviewHeight,
                        largest
                )
                // We fit the aspect ratio of TextureView to the size of preview we picked.
                if (activity.resources.configuration.orientation == Configuration.ORIENTATION_LANDSCAPE)
                {
                    textureVw?.setAspectRatio(previewSize.width, previewSize.height)
                }
                else
                {
                    textureVw?.setAspectRatio(previewSize.height, previewSize.width)
                }
                // Check if the flash is supported.
                flashIsSupported = characteristics.get(CameraCharacteristics.FLASH_INFO_AVAILABLE) ==
                        true
                this.currentCameraID = cameraId
                // We've found a viable camera and finished setting up member variables,
                // so we don't need to iterate through other available cameras.
                return
            }
        }
        catch (e: CameraAccessException)
        {
            print(e.toString())
        }
        catch (e: NullPointerException)
        {
            // Currently an NPE is thrown when the Camera2API is used but not supported on the
            // device this code runs.
            print("CAMERA ERROR DIALOG")
        }
    }

    /**
     * Opens the camera specified by this class' current camera ID.
     */
    private fun activateCurrentCamera(width: Int, height: Int)
    {
        val act = activity
        val mngr = act?.getSystemService(Context.CAMERA_SERVICE) as? CameraManager

        //Make sure appropriate stuff exists
        if (act == null || mngr == null)
        {
//            return
            TODO()  //Report the null
        }
        //Check if permissions exist
        if (ContextCompat.checkSelfPermission(act, Manifest.permission.CAMERA)
                != PackageManager.PERMISSION_GRANTED
        )
        {
            if (ActivityCompat.shouldShowRequestPermissionRationale(
                            act,
                            Manifest.permission.CAMERA
                    )
            )
            {
                delegate?.cameraControlDidWantToExplainWhyCameraPermissionsAreNeeded(reason = "reason")
                TODO() //ask for permissiosns
            }
            else
            {
                ActivityCompat.requestPermissions(
                        act, arrayOf(Manifest.permission.CAMERA),
                        CAMERA_PERMISSION_REQ_CODE
                )
            }
            return
        }
        //Proceed to set up camera(s)
        setUpCameraOutputs(width = width, height = height)
        configureTransform(width, height)
        try
        {
            if (!cameraOpenCloseSemaphore.tryAcquire(2500, TimeUnit.MILLISECONDS))
            {
                throw RuntimeException("Time out waiting to lock camera opening.")
                TODO() //Handleleee
            }
            mngr.openCamera(currentCameraID, cameraStateCallback, backgroundHandler)
        }
        catch (e: CameraAccessException)
        {
            e.printStackTrace()
            TODO() //Log dis
        }
        catch (e: InterruptedException)
        {
            throw RuntimeException("Interrupted while trying to lock camera opening.", e)
        }
    }

    /**
     * Closes the current camera specified by this class' current camera ID.
     */
    private fun deactivateCurrentCamera()
    {
        try
        {
            cameraOpenCloseSemaphore.acquire()
            capSesh?.close()
            capSesh = null

            currentCameraDevice?.close()
            currentCameraDevice = null

            imgReader?.close()
            imgReader = null
        }
        catch (e: InterruptedException)
        {
            throw RuntimeException("Interrupted while trying to lock camera closing.", e)
            TODO() //alskdjflksdjflk
        }
        finally
        {
            cameraOpenCloseSemaphore.release()
        }
    }

    /**
     * Starts a background thread and its [Handler].
     */
    private fun startBackgroundThread()
    {
        val newThread = HandlerThread("CameraBackground")
        backgroundThread = newThread
        newThread.start()
        backgroundHandler = Handler(newThread.looper)
    }

    /**
     * Stops the background thread and its [Handler].
     */
    private fun stopBackgroundThread()
    {
        backgroundThread?.quitSafely()
        try
        {
            backgroundThread?.join()
            backgroundThread = null
            backgroundHandler = null
        }
        catch (e: InterruptedException)
        {
            e.printStackTrace()
            TODO()
        }
    }

    /**
     * Creates a new capture session for the camera preview.
     */
    private fun createCameraPreviewSession()
    {
        try
        {
            val surfaceTexture: SurfaceTexture? = textureVw?.surfaceTexture
            val currentCamera: CameraDevice? = currentCameraDevice
            val imgReader: ImageReader? = imgReader

            if (surfaceTexture == null || currentCamera == null || imgReader == null)
            {
                return
                TODO()  //alsdkjf;alksdjf
            }

            //Configure the size of default buffer to be the size of desired camera preview
            surfaceTexture.setDefaultBufferSize(previewSize.width, previewSize.height)

            //This is the output surface we need to start the preview
            val surface = Surface(surfaceTexture)

            //Set up a capture request builder with the newly created Surface object
            previewReqBuilder = currentCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW)
            previewReqBuilder?.addTarget(surface)

            //Now create a capture session for the visual preview and for the image reader
            currentCamera.createCaptureSession(
                    mutableListOf(surface, imgReader.surface),
                    object : CameraCaptureSession.StateCallback()
                    {
                        override fun onConfigureFailed(session: CameraCaptureSession)
                        {
                            TODO()//Say that the cap sesh initialization failed
                        }

                        override fun onConfigured(session: CameraCaptureSession)
                        {
                            val previewReqBuilder = previewReqBuilder
                            if (previewReqBuilder == null)
                            {
                                return
                                //TODO()
                            }
                            //The camera is already closed
                            if (currentCameraDevice == null)
                            {
                                return
                            }

                            //When the session is ready, start the preview
                            capSesh = session
                            try
                            {
                                //Set auto focus mode
                                previewReqBuilder.set(
                                        CaptureRequest.CONTROL_AF_MODE,
                                        CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE
                                )
                                //Flash is automatically enabled when necessary
                                setAutoFlash(previewReqBuilder)

                                //Start displaying the preview safely
                                previewReq = previewReqBuilder.build()
                                val localizedPreviewReq = previewReq
                                if (localizedPreviewReq != null)
                                {
                                    capSesh?.setRepeatingRequest(
                                            localizedPreviewReq, capSeshCallback, backgroundHandler
                                    )
                                }
                            }
                            catch (e: CameraAccessException)
                            {
                                e.printStackTrace()
                                TODO()  //alskdjf;akdsjf
                            }
                        }
                    },
                    null
            )
        }
        catch (e: CameraAccessException)
        {
            e.printStackTrace()
            TODO()
        }
    }

    /**
     * Configures the necessary matrix transformation to the texture view.
     * This method should be called after the camera preview size is determined and also when the
     * size of the texture view is fixed.
     *
     * @param viewWidth  The width of `mTextureView`
     * @param viewHeight The height of `mTextureView`
     */
//    private fun configureTransform(viewWidth: Int, viewHeight: Int)
//    {
//        val act = activity
//        val textureView = textureVw
//
//        if (textureView == null || act == null)
//        {
//            TODO()
//            return
//        }
//        val rotation = act.windowManager.defaultDisplay.rotation
//        val matrix = Matrix()
//        val viewRect = RectF(0f, 0f, viewWidth.toFloat(), viewHeight.toFloat())
//        val bufferRect = RectF(
//            0f, 0f, previewSize.height.toFloat(),
//            previewSize.width.toFloat()
//        )
//        val centerX = viewRect.centerX()
//        val centerY = viewRect.centerY()
//        if (Surface.ROTATION_90 == rotation || Surface.ROTATION_270 == rotation)
//        {
//            bufferRect.offset(
//                centerX - bufferRect.centerX(),
//                centerY - bufferRect.centerY()
//            )
//            matrix.setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL)
//            val scale = Math.max(
//                viewHeight.toFloat() / previewSize.height,
//                viewWidth.toFloat() / previewSize.width
//            )
//            matrix.postScale(scale, scale, centerX, centerY);
//            matrix.postRotate(90f * (rotation - 2).toFloat(), centerX, centerY)
//        }
//        else if (Surface.ROTATION_180 == rotation)
//        {
//            matrix.postRotate(180f, centerX, centerY)
//        }
//        textureView.setTransform(matrix)
//    }
    private fun configureTransform(viewWidth: Int, viewHeight: Int)
    {
        val activity = activity ?: return
        val rotation = activity.windowManager.defaultDisplay.rotation
        val matrix = Matrix()
        val viewRect = RectF(0f, 0f, viewWidth.toFloat(), viewHeight.toFloat())
        val bufferRect = RectF(0f, 0f, previewSize.height.toFloat(), previewSize.width.toFloat())
        val centerX = viewRect.centerX()
        val centerY = viewRect.centerY()
        if (Surface.ROTATION_90 == rotation || Surface.ROTATION_270 == rotation)
        {
            bufferRect.offset(centerX - bufferRect.centerX(), centerY - bufferRect.centerY())
            val scale = Math.max(
                    viewHeight.toFloat() / previewSize.height,
                    viewWidth.toFloat() / previewSize.width
            )
            with(matrix) {
                setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL)
                postScale(scale, scale, centerX, centerY)
                postRotate((90 * (rotation - 2)).toFloat(), centerX, centerY)
            }
        }
        else if (Surface.ROTATION_180 == rotation)
        {
            matrix.postRotate(180f, centerX, centerY)
        }
        textureVw?.setTransform(matrix)
    }

    /**
     * The first step for a still image capture is to lock the focus.
     */
    private fun lockFocus()
    {
        try
        {
            val reqBuilder = previewReqBuilder ?: return

            //Tell the camera to lock its focus
            reqBuilder.set(
                    CaptureRequest.CONTROL_AF_TRIGGER,
                    CameraMetadata.CONTROL_AF_TRIGGER_START
            )
            //Wait for the lock
            currentCamState = STATE_WAITING_LOCK
            capSesh?.capture(reqBuilder.build(), capSeshCallback, backgroundHandler)
        }
        catch (e: CameraAccessException)
        {
            e.printStackTrace()
            TODO()
        }
    }

    /**
     * Run the pre-capture sequence for capturing a still image. This should be called when a
     * response from locking focus happens in the capture session callback.
     */
    private fun runPrecaptureSequence()
    {
        try
        {
            val reqBuilder = previewReqBuilder ?: return

            //Trigger the camera
            reqBuilder.set(
                    CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                    CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_START
            )

            //Tell the cap session callback to wait for the pre-capture sequence to set
            currentCamState = STATE_WAITING_PRECAPTURE
            capSesh?.capture(reqBuilder.build(), capSeshCallback, backgroundHandler)
        }
        catch (e: CameraAccessException)
        {
            e.printStackTrace()
            TODO()
        }
    }

    /**
     * Capture a still picture. This method should be called when a response happens from
     * locking focus occurs in the capture session callback.
     */
    private fun captureStillPicture()
    {
        try
        {
            val act = activity
            val theCamera = currentCameraDevice
            val imgReader = imgReader
            val capSesh = capSesh

            if (act == null || theCamera == null || imgReader == null || capSesh == null)
            {
                println("Something was null when attempting to capture still picture")
                TODO()
                return
            }
            //Create a capture request builder to take the photo
            val captureBuilder = theCamera.createCaptureRequest(
                    CameraDevice.TEMPLATE_STILL_CAPTURE
            )
            captureBuilder.addTarget(imgReader.surface)

            //Use the same AE and AF modes as the preview
            captureBuilder.set(
                    CaptureRequest.CONTROL_AF_MODE,
                    CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE
            )
            setAutoFlash(captureBuilder)

            //Orientation
            val rotation = act.windowManager.defaultDisplay.rotation
            captureBuilder.set(CaptureRequest.JPEG_ORIENTATION, getOrientation(rotation))

            val capCallback = object : CameraCaptureSession.CaptureCallback()
            {
                override fun onCaptureCompleted(
                    session: CameraCaptureSession,
                    request: CaptureRequest,
                    result: TotalCaptureResult
                )
                {
                    println("capture completed")
                    unlockFocus()   //TODO do something with the file
                    lastPicTaken = Uri.fromFile(oFile)
                    println("saved to $lastPicTaken")
                    super.onCaptureCompleted(session, request, result)
                    delegate?.cameraControlFinishedTakingPicture()
                }
            }
            capSesh.stopRepeating()
            capSesh.abortCaptures()
            println("commencing capture")
            try
            {
                capSesh.capture(captureBuilder.build(), capCallback, null)
            }
            catch (e: Exception)
            {
                println("CAPTURE FAILURE")
            }
        }
        catch (e: CameraAccessException)
        {
            e.printStackTrace()
            TODO()
        }
    }

    /**
     * Retrieves the JPEG orientation from the specified screen rotation.
     *
     * @param rotation The screen rotation.
     * @return The JPEG orientation (one of 0, 90, 270, and 360)
     */
    private fun getOrientation(rotation: Int): Int
    {
        val sensorOrientation = sensorOrientation
        val manufacturerOrientation = ORIENTATIONS[rotation]
        if (sensorOrientation == null || manufacturerOrientation == null)
        {
            throw java.lang.NullPointerException("Sigh")
            TODO()
        }
        //Sensor orientation is 90 for most devices, or 270 for some devices (eg. Nexus 5X)
        //Taking that into account, gotta rotate the JPEG properly.
        //For devices with orientation of 90, simply return the mapping from ORIENTATIONS.
        //For devices with orientation of 270, rotate the JPEG 180 degrees
        return (manufacturerOrientation + sensorOrientation + 270) % 360
    }

    /**
     * Unlock the focus. This method should be called when the still image capture sequence is
     * done.
     */
    private fun unlockFocus()
    {
        try
        {
            val previewReqBuilder = previewReqBuilder
            val previewReq = previewReq
            if (previewReqBuilder == null || previewReq == null)
            {
                return
                TODO()
            }
            //Reset the auto-focus trigger
            previewReqBuilder.set(
                    CaptureRequest.CONTROL_AF_TRIGGER,
                    CameraMetadata.CONTROL_AF_TRIGGER_CANCEL
            )
            setAutoFlash(previewReqBuilder)
            capSesh?.capture(previewReqBuilder.build(), capSeshCallback, backgroundHandler)

            //Revert to normal preview state
            currentCamState = STATE_PREVIEW
            capSesh?.setRepeatingRequest(previewReq, capSeshCallback, backgroundHandler)
        }
        catch (e: CameraAccessException)
        {
            e.printStackTrace()
            TODO()
        }
    }

    private fun setAutoFlash(requestBuilder: CaptureRequest.Builder)
    {
        if (flashIsSupported)
        {
            requestBuilder.set(
                    CaptureRequest.CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH
            )
        }
    }

    /**
     * Determines if the dimensions are swapped given the phone's current rotation.
     *
     * @param displayRotation The current rotation of the display
     *
     * @return true if the dimensions are swapped, false otherwise.
     */
    private fun areDimensionsSwapped(displayRotation: Int): Boolean
    {
        var swappedDimensions = false
        when (displayRotation)
        {
            Surface.ROTATION_0, Surface.ROTATION_180  ->
            {
                if (sensorOrientation == 90 || sensorOrientation == 270)
                {
                    swappedDimensions = true
                }
            }
            Surface.ROTATION_90, Surface.ROTATION_270 ->
            {
                if (sensorOrientation == 0 || sensorOrientation == 180)
                {
                    swappedDimensions = true
                }
            }
            else                                      ->
            {
                println("Display rotation is invalid: $displayRotation")
            }
        }
        return swappedDimensions
    }

    //endregion
}